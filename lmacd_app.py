# ---------------------------------------------------------------
# lmacd_app.py (FINAL INTEGRATED VERSION - THEORETICALLY ENRICHED)
# Streamlit demo: L-MACD multi-step CAPTCHA (Adversarial, Semantic, Handwritten)
# ---------------------------------------------------------------
# Author: Mukul Sangwan (Enhanced by Gemini)
# Description:
# A clean, publication-grade Streamlit interface demonstrating the adaptive
# CAPTCHA framework with multi-step challenge, improved logging, and rich theoretical context.
# ---------------------------------------------------------------
import subprocess
subprocess.run(["pip", "show", "pytesseract"])

import streamlit as st
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import numpy as np
import cv2
import pytesseract
import random
import os
import csv
import math
import difflib
from datetime import datetime
import base64
import pandas as pd
import json

# -----------------------------
# CONFIGURATION
# -----------------------------
st.set_page_config(
    page_title="L-MACD: Adaptive CAPTCHA Defense",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Global variables/constants
PLOTS_DIR = "plots"
DATA_LOG = "verification_log.csv"

if not os.path.exists(PLOTS_DIR):
    os.makedirs(PLOTS_DIR)

# Light, minimalistic theme
st.markdown("""
    <style>
    body { background-color: #fafafa; }
    .block-container { padding-top: 1rem; padding-bottom: 1rem; }
    img { border-radius: 8px; }
    div[data-testid="stImage"] { margin-bottom: 20px; }
    .step-container { border: 1px solid #ddd; padding: 15px; border-radius: 8px; margin-bottom: 15px; }
    .correct-tile { border: 3px solid #4CAF50; border-radius: 8px; padding: 5px;}
    .incorrect-tile { border: 3px solid #f44336; border-radius: 8px; padding: 5px;}
    </style>
""", unsafe_allow_html=True)

# --- Session State Initialization ---
if 'step' not in st.session_state:
    st.session_state.step = 0
if 'adv_params' not in st.session_state:
    st.session_state.adv_params = (3.0, 0.5, 15)
if 'log_row' not in st.session_state:
    st.session_state.log_row = {}
if 'semantic_selections' not in st.session_state:
    st.session_state.semantic_selections = []


# -----------------------------
# UTILITY AND LOGGING FUNCTIONS
# ----------------------------------------------------

def choose_font(size=40):
    candidates = ["DejaVuSans.ttf", "Arial.ttf", "/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf", "/Library/Fonts/Arial.ttf"]
    for f in candidates:
        try:
            return ImageFont.truetype(f, size)
        except Exception:
            continue
    return ImageFont.load_default()

def text_size(font, text):
    try:
        bbox = font.getbbox(text)
        w = bbox[2] - bbox[0]
        h = bbox[3] - bbox[1]
        return w, h
    except Exception:
        try:
            return font.getsize(text)
        except Exception:
            return (len(text) * font.size // 2, font.size)

def normalize_text(s: str):
    return "".join(s.lower().strip().split())

def fuzzy_match(a: str, b: str, thresh=0.7):
    a = a or ""
    b = b or ""
    if a == b:
        return True
    r = difflib.SequenceMatcher(None, normalize_text(a), normalize_text(b)).ratio()
    return r >= thresh

def append_log_row(row, path=DATA_LOG):
    """
    Appends a row to the log file, using the simplified header format.
    """
    header = ["timestamp", "adv_human", "sem_human", "hw_human",
              "adv_bot", "sem_bot", "hw_bot", "params"]
    file_exists = os.path.exists(path)
    with open(path, "a", newline="") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(header)
        writer.writerow(row)


# -----------------------------
# CAPTCHA GENERATORS & BOT SOLVERS (Unchanged)
# -----------------------------

def generate_adversarial(text="LMACD", size=(320,110), p_distort=3.0, p_noise=0.5, p_rotate=12):
    W, H = size
    img = Image.new("RGB", (W, H), (255, 255, 255))
    draw = ImageDraw.Draw(img)
    font = choose_font(48)
    offset_x = 12
    for i, ch in enumerate(text):
        jitter_x = random.randint(-3, 3)
        jitter_y = random.randint(-8, 8)
        w, h = text_size(font, ch)
        x = offset_x + i * (w + 4) + jitter_x
        y = (H - h) // 2 + jitter_y
        draw.text((x, y), ch, font=font, fill=(0, 0, 0))
    img = img.rotate(p_rotate * random.choice([-1, 1]), resample=Image.BICUBIC, expand=0, fillcolor=(255, 255, 255))
    arr = np.array(img)
    new = np.zeros_like(arr)
    amplitude = max(1, int(round(p_distort)))
    freq = 18.0
    for y in range(H):
        shift = int(amplitude * math.sin(2 * math.pi * y / freq))
        new[y] = np.roll(arr[y], shift, axis=0)
    noise = np.random.randint(0, int(120 * p_noise), (H, W, 3), dtype=np.uint8)
    new = np.clip(new + noise, 0, 255).astype(np.uint8)
    img = Image.fromarray(new)
    img = img.filter(ImageFilter.GaussianBlur(radius=max(0.5, p_noise)))
    return img

def generate_handwritten(text="verify", size=(320,110)):
    W, H = size
    img = Image.new("RGB", (W, H), (255, 255, 255))
    font = choose_font(46)
    x = 12
    for ch in text:
        canvas = Image.new("RGBA", (80, 80), (0, 0, 0, 0))
        cd = ImageDraw.Draw(canvas)
        cd.text((2, 2), ch, font=font, fill=(10, 10, 10))
        angle = random.uniform(-22, 18)
        canvas = canvas.rotate(angle, resample=Image.BICUBIC, expand=1)
        y = random.randint(14, 36)
        img.paste(canvas, (x, y), canvas)
        w, _ = text_size(font, ch)
        x += int(w * 0.9) + random.randint(-1, 5)
    pix = img.load()
    for _ in range(int(W * H * 0.0025)):
        rx = random.randint(0, W - 1)
        ry = random.randint(0, H - 1)
        pix[rx, ry] = (random.randint(0, 30),) * 3
    img = img.filter(ImageFilter.GaussianBlur(radius=0.6))
    return img

def generate_semantic_grid(target_label="car", grid_size=(3, 3), image_size=(120, 120)):
    labels = ["car", "tree", "bicycle", "bus", "dog", "cat", "boat", "house", "flower"]
    if target_label not in labels:
        target_label = random.choice(labels)
    items = [random.choice(labels) for _ in range(grid_size[0] * grid_size[1])]
    target_count = random.randint(1, 3)
    target_indices = random.sample(range(len(items)), target_count)
    for i in target_indices:
        items[i] = target_label

    imgs = []
    for lbl in items:
        img = Image.new("RGB", image_size, (255, 255, 255))
        d = ImageDraw.Draw(img)
        w, h = image_size
        if lbl in ["car", "bus"]:
            color = (200, 40, 40) if lbl == "car" else (40, 80, 200)
            d.rectangle([(10, 40), (w - 10, 70)], fill=color)
            d.ellipse([(20, 68), (40, 88)], fill=(0, 0, 0))
            d.ellipse([(w - 40, 68), (w - 20, 88)], fill=(0, 0, 0))
        elif lbl == "bicycle":
            d.ellipse([(10, 30), (40, 60)], outline=(0, 0, 0), width=3)
            d.ellipse([(w - 40, 30), (w - 10, 60)], outline=(0, 0, 0), width=3)
            d.line([(30, 45), (w - 30, 45)], fill=(0, 0, 0), width=3)
        elif lbl == "tree":
            d.rectangle([(w // 2 - 8, w // 2), (w // 2 + 8, h - 10)], fill=(120, 70, 20))
            d.ellipse([(w // 2 - 35, 20), (w // 2 + 35, 90)], fill=(30, 120, 30))
        elif lbl in ["dog", "cat"]:
            d.ellipse([(w // 2 - 30, 20), (w // 2 + 30, 80)], fill=(150, 100, 80))
        elif lbl == "boat":
            d.polygon([(10, h - 20), (w - 10, h - 20), (w // 2, h - 50)], fill=(20, 80, 160))
        elif lbl == "house":
            d.rectangle([(20, h // 2), (w - 20, h - 10)], fill=(200, 180, 80))
            d.polygon([(10, h // 2), (w // 2, 10), (w - 10, h // 2)], fill=(180, 80, 80))
        elif lbl == "flower":
            d.ellipse([(w // 2 - 15, 20), (w // 2 + 15, 60)], fill=(220, 20, 140))
            d.rectangle([(w // 2 - 3, 60), (w // 2 + 3, h - 10)], fill=(30, 120, 30))
        imgs.append((lbl, img))

    correct_indices = [i for i, (lbl, _) in enumerate(imgs) if lbl == target_label]
    return imgs, target_label, correct_indices

def ocr_bot_read(pil_img):
    try:
        proc = preprocess_for_ocr(pil_img)
        proc2 = cv2.bitwise_not(proc)
        pil_proc = Image.fromarray(proc2)
        config = "--psm 8 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789"
        txt = pytesseract.image_to_string(pil_proc, config=config)
        txt = "".join([c for c in txt if c.isalnum()])
        return txt.strip()
    except Exception:
        return ""

def template_match_semantic(target_label, grid_imgs):
    p_distort, p_noise, p_rotate = st.session_state.adv_params
    bot_success_prob = max(0.2, 0.95 - (p_noise * 0.5))
    correct_indices = [i for i, (lbl, _) in enumerate(grid_imgs) if lbl == target_label]
    matched_indices = set()

    if random.random() < bot_success_prob:
        matched_indices = set(correct_indices)
    else:
        if len(correct_indices) > 0:
            if random.random() < 0.5:
                matched_indices = set(random.sample(correct_indices, max(1, len(correct_indices) - 1)))
            else:
                wrong_index = random.choice([i for i in range(len(grid_imgs)) if i not in correct_indices] + correct_indices)
                matched_indices = set(random.sample(correct_indices, max(1, len(correct_indices) - 1))) | {wrong_index}
        else:
            matched_indices = {random.randrange(len(grid_imgs))}

    bot_correct_ok = (len(matched_indices) == len(correct_indices)) and (all(i in matched_indices for i in correct_indices))
    return matched_indices, bot_correct_ok


# ---------------------------------------------------------------
# L-MACD MULTI-STEP HANDLER (Verification Logic)
# ---------------------------------------------------------------

def run_simulation(p_distort, p_noise, p_rotate):
    """Regenerates all CAPTCHA stages and resets the simulation."""
    st.session_state.step = 1
    
    p_d_rnd = round(p_distort, 2)
    p_n_rnd = round(p_noise, 2)
    p_r_rnd = int(p_rotate)
    st.session_state.adv_params = (p_distort, p_noise, p_rotate)

    # Stage 1: Adversarial Text CAPTCHA
    text_choices = ["AI2025", "LMACD", "SECURE", "VERIFY"]
    st.session_state.adv_text_actual = random.choice(text_choices)
    st.session_state.adv_img = generate_adversarial(
        text=st.session_state.adv_text_actual,
        p_distort=p_distort,
        p_noise=p_noise,
        p_rotate=p_rotate
    )

    # Stage 2: Semantic Grid CAPTCHA
    labels = ["car", "tree", "bicycle", "bus", "dog", "cat", "boat", "house", "flower"]
    target_label = random.choice(labels)
    grid_imgs, target_label_actual, correct_indices = generate_semantic_grid(target_label=target_label)
    st.session_state.sem_target_actual = target_label_actual
    st.session_state.sem_grid_imgs = grid_imgs
    st.session_state.sem_correct_indices_display = [i + 1 for i in correct_indices]
    st.session_state.sem_correct_indices = correct_indices
    st.session_state.semantic_selections = []

    # Stage 3: Handwritten Text CAPTCHA
    st.session_state.hw_text_actual = random.choice(["hello", "world", "write", "final"])
    st.session_state.hw_img = generate_handwritten(text=st.session_state.hw_text_actual)

    # Clear previous human/bot inputs
    st.session_state.human_adv_input = ""
    st.session_state.human_hw_input = ""
    
    # Initialize log_row for current run with formatted parameters
    st.session_state.log_row = {
        "timestamp": datetime.now().strftime("20%y-%m-%d %H:%M:%S"),
        "adv_human_ok": 0, "sem_human_ok": 0, "hw_human_ok": 0,
        "adv_bot_ok": 0, "sem_bot_ok": 0, "hw_bot_ok": 0,
        "params": f"{{'p_distort': {p_d_rnd}, 'p_noise': {p_n_rnd}, 'p_rotate': {p_r_rnd}}}"
    }

def verify_step_1():
    """Verify Adversarial Text. Continues to Step 2 regardless of human success."""
    if not st.session_state.human_adv_input:
        st.warning("Please enter the text from the image.")
        return

    human_ok = fuzzy_match(st.session_state.human_adv_input, st.session_state.adv_text_actual, thresh=0.8)
    st.session_state.log_row["adv_human_ok"] = 1 if human_ok else 0

    bot_read_text = ocr_bot_read(st.session_state.adv_img)
    bot_ok = fuzzy_match(bot_read_text, st.session_state.adv_text_actual, thresh=0.8)
    st.session_state.log_row["adv_bot_ok"] = 1 if bot_ok else 0

    if human_ok:
        st.success("‚úÖ Stage 1 (Adversarial Text) Passed by Human! Moving to Stage 2.")
    else:
        st.warning(f"‚ö†Ô∏è Stage 1 (Adversarial Text) Failed. Moving to Stage 2 anyway.")

    st.session_state.step = 2
    st.session_state.bot_adv_result = f"Bot read: **'{bot_read_text}'** (Success: {'Yes' if bot_ok else 'No'})"

def verify_step_2(selected_indices):
    """Verify Semantic Grid. Continues to Step 3 regardless of human success."""
    if st.session_state.step == 2 and not selected_indices:
        st.warning("Please select at least one image.")
        return

    st.session_state.semantic_selections = selected_indices
    selected_indices_0_indexed = [i for i in selected_indices]
    correct_indices_0_indexed = st.session_state.sem_correct_indices
    human_ok = (len(selected_indices_0_indexed) == len(correct_indices_0_indexed)) and \
               (all(i in selected_indices_0_indexed for i in correct_indices_0_indexed))
    st.session_state.log_row["sem_human_ok"] = 1 if human_ok else 0

    bot_matched_indices, bot_ok = template_match_semantic(
        st.session_state.sem_target_actual,
        st.session_state.sem_grid_imgs
    )
    st.session_state.log_row["sem_bot_ok"] = 1 if bot_ok else 0

    if human_ok:
        st.success("‚úÖ Stage 2 (Semantic Grid) Passed by Human! Moving to Stage 3.")
    else:
        st.warning(f"‚ö†Ô∏è Stage 2 (Semantic Grid) Failed. Moving to Stage 3 anyway.")

    st.session_state.step = 3
    st.session_state.bot_sem_result = f"Bot matched {len(bot_matched_indices)} tiles (Success: {'Yes' if bot_ok else 'No'})"

def verify_step_3():
    """Verify Handwritten Text and finalize the process."""
    if not st.session_state.human_hw_input:
        st.warning("Please enter the text from the image.")
        return

    human_ok = fuzzy_match(st.session_state.human_hw_input, st.session_state.hw_text_actual, thresh=0.85)
    st.session_state.log_row["hw_human_ok"] = 1 if human_ok else 0

    bot_read_text = ocr_bot_read(st.session_state.hw_img)
    bot_ok = fuzzy_match(bot_read_text, st.session_state.hw_text_actual, thresh=0.85)
    st.session_state.log_row["hw_bot_ok"] = 1 if bot_ok else 0

    st.session_state.bot_hw_result = f"Bot read: **'{bot_read_text}'** (Success: {'Yes' if bot_ok else 'No'})"

    # --- Log and Finalize ---
    log = st.session_state.log_row
    
    final_log_row = [
        log["timestamp"],
        "TRUE" if log["adv_human_ok"] == 1 else "FALSE",
        "TRUE" if log["sem_human_ok"] == 1 else "FALSE",
        "TRUE" if log["hw_human_ok"] == 1 else "FALSE",
        "TRUE" if log["adv_bot_ok"] == 1 else "FALSE",
        "TRUE" if log["sem_bot_ok"] == 1 else "FALSE",
        "TRUE" if log["hw_bot_ok"] == 1 else "FALSE",
        log["params"]
    ]
    append_log_row(final_log_row)

    total_passed = log["adv_human_ok"] + log["sem_human_ok"] + log["hw_human_ok"]

    if total_passed == 3:
        st.balloons()
        st.success(f"üéâ **VERIFICATION COMPLETE!** You passed **{total_passed}/3** stages. Full human pass.")
    else:
        st.info(f"üëç **VERIFICATION COMPLETE!** You passed **{total_passed}/3** stages. Results logged.")

    st.session_state.step = 4
    st.rerun()


# ---------------------------------------------------------------
# TITLE AND NAVIGATION
# ---------------------------------------------------------------
st.title("üß© Learning-Based Multi-Agent CAPTCHA Defense (L-MACD)")
st.caption("An Adaptive, Explainable, and Reinforcement Learning-Driven CAPTCHA Framework")

st.markdown("""
L-MACD combines **Machine Learning (ML)**, **Reinforcement Learning (RL)**, and **Explainable AI (XAI)** to create an **adaptive CAPTCHA system** that evolves in real time against AI-based solvers.
""")

# SIDEBAR NAVIGATION
st.sidebar.header("üìë Navigation")
section = st.sidebar.radio(
    "Select Section",
    [
        "1Ô∏è‚É£ Overview & Motivation",
        "2Ô∏è‚É£ System Architecture",
        "3Ô∏è‚É£ Interactive Simulation",
        "4Ô∏è‚É£ Results & Visualizations",
        "5Ô∏è‚É£ Use Case Scenarios",
        "6Ô∏è‚É£ Explainability (XAI)",
        "7Ô∏è‚É£ Generate Report / Export",
        "8Ô∏è‚É£ Conclusion"
    ]
)

# ---------------------------------------------------------------
# SECTION 1 ‚Äî OVERVIEW
# ---------------------------------------------------------------
if section.startswith("1Ô∏è‚É£"):
    st.header("1Ô∏è‚É£ Overview & Motivation")
    
    # --- EXPANDED THEORY ---
    st.markdown("""
    Modern **AI solvers**‚Äîespecially multimodal Large Language Models (LLMs) like GPT-4V‚Äîcan now decode traditional CAPTCHAs with alarmingly high accuracy, often exceeding **98% success rates**. This phenomenon represents a significant **reversal of the Turing Test** in the context of security tasks.
    
    **L-MACD** addresses this fundamental security vulnerability by introducing a new, adaptive defense paradigm. It acts as a **dynamic friction layer** that learns the optimal visual complexity to maximize the defense metric, $\mathbf{AGE}_{\text{eff}}$, while adhering to strict human usability constraints. The system constantly optimizes its *action space* ($\mathbf{p_{\text{distort}}}, \mathbf{p_{\text{noise}}}, \mathbf{p_{\text{rotate}}}$) based on real-time feedback loops from simulated and live attacks.
    """)
    # --- END EXPANDED THEORY ---
    
    st.markdown("---")
    st.subheader("The Three-Stage L-MACD Challenge (G4)")
    st.markdown("""
    The core defense relies on a **multi-modal, multi-step challenge** (G4) to introduce multiple, asynchronous points of failure for automated agents:
    1.  **Adversarial Text (G1):** Uses heavy distortion and noise to neutralize **Optical Character Recognition (OCR)** engines and basic deep learning segmentation models.
    2.  **Semantic Grid (G2):** Requires conceptual understanding (e.g., object recognition), which defeats generic text-only AI solvers and forces reliance on computationally expensive vision models.
    3.  **Handwritten Text (G3):** Uses dynamic font variations and subtle noise, challenging AI models trained only on clean, standard font datasets, thus raising the **computational cost of attack (CoA)**.
    """)


# ---------------------------------------------------------------
# SECTION 2 ‚Äî ARCHITECTURE
# ---------------------------------------------------------------
elif section.startswith("2Ô∏è‚É£"):
    st.header("2Ô∏è‚É£ System Architecture")
    st.image(os.path.join(PLOTS_DIR, "1_AGEeff_comparison.png"),
              caption="L-MACD Reinforcement Learning Framework Overview (Placeholder for RL Diagram)",
              use_container_width=True)
    st.markdown("""
    The L-MACD architecture is a closed-loop **Reinforcement Learning (RL)** system featuring three primary agents:
    
    * **Generator (G):** The **RL Agent** that outputs the action space (visual parameters $\mathbf{p_{\text{params}}}$).
    * **Attacker (A):** Simulates sophisticated AI solvers, providing adversarial feedback ($\text{SR}_{\text{bot}}$).
    * **Evaluator (E):** Computes the **Reward Signal** using the core metric:
        $$ \text{AGE}_{\text{eff}} = \text{SR}_{\text{human}} - \text{SR}_{\text{bot}} $$
    The system's objective function is to **maximize the cumulative reward** derived from a high $\text{AGE}_{\text{eff}}$, ensuring the defense strategy is always evolving against the current threat landscape.
    """)


# ---------------------------------------------------------------
# SECTION 3 ‚Äî INTERACTIVE SIMULATION
# ---------------------------------------------------------------
elif section.startswith("3Ô∏è‚É£"):
    st.header("3Ô∏è‚É£ Interactive L-MACD Multi-Step Simulation")
    st.write("Adjust the parameters (the RL agent's 'Action Space') to observe how the visual challenge changes and how key defense metrics are affected.")

    col_sim_controls, col_sim_metrics = st.columns([2, 1])

    with col_sim_controls:
        with st.expander("‚öôÔ∏è **Adjust RL Action Space Parameters** (Controls Challenge Difficulty)", expanded=st.session_state.step == 0):
            col1, col2, col3 = st.columns(3)
            with col1:
                p_distort_slider = st.slider("Distortion ($\mathbf{p_{\text{distort}}}$)", 1.0, 5.0, 3.0, 0.1, key="p_distort_slider")
            with col2:
                p_noise_slider = st.slider("Noise ($\mathbf{p_{\text{noise}}}$)", 0.2, 1.0, 0.5, 0.05, key="p_noise_slider")
            with col3:
                p_rotate_slider = st.slider("Rotation (degrees)", 0, 30, 15, 1, key="p_rotate_slider")

            if st.button("Generate New L-MACD Challenge", key="generate_btn"):
                run_simulation(p_distort_slider, p_noise_slider, p_rotate_slider)
                st.rerun()

        if st.session_state.step == 0:
            st.info("Click 'Generate New L-MACD Challenge' to begin the 3-step verification process.")

    with col_sim_metrics:
        st.subheader("üéØ RL Agent's Goal (Simulated)")
        
        p_d, p_n, p_r = st.session_state.adv_params
        
        sim_sr_human = round(max(0.70, 0.95 - (p_n * 0.1) - (abs(p_r - 15) * 0.003)), 3)
        sim_sr_bot = round(max(0.01, 0.95 - (p_n * 0.55) - (p_d * 0.08) - (p_r * 0.005)), 3)
        sim_age_eff = round(max(0, sim_sr_human - sim_sr_bot), 3)
        
        sim_reward = round((sim_age_eff * 100) - (p_n * 5) - (p_d * 1.5), 1)
        sim_tts = round(8.0 + (p_n * 4) + (p_d * 1.5), 1)

        df = pd.DataFrame({
            'Metric': ['SR_Human', 'SR_Bot', 'AGE_eff'],
            'Value': [sim_sr_human, sim_sr_bot, sim_age_eff],
            'Type': ['Human', 'Bot', 'Defense']
        })

        st.bar_chart(df.set_index('Metric')['Value'], height=150)
        
        col_r, col_t = st.columns(2)
        col_r.metric("üí∞ RL Reward Signal", f"{sim_reward:.1f}", 
                     help="RL reward maximizes AGE_eff while minimizing parameter complexity.")
        col_t.metric("‚è±Ô∏è Human TTS (Sec)", f"{sim_tts:.1f}", 
                     help="Simulated time-to-solve, showing the human usability constraint.")
        st.markdown("---")


    # --- Stage 1: Adversarial Text ---
    if st.session_state.step >= 1:
        st.subheader("1. Adversarial Text CAPTCHA (G1)")
        st.markdown(f'<div class="step-container">', unsafe_allow_html=True)
        st.image(st.session_state.adv_img, caption="What text do you see?", width=320)
        st.text_input(
            f"Enter Text from Image [Actual: '{st.session_state.adv_text_actual}']",
            key="human_adv_input",
            disabled=(st.session_state.step != 1),
        )
        if st.session_state.step == 1:
            if st.button("Verify Stage 1 & Continue", key="verify_1_btn"):
                verify_step_1()
                st.rerun()
        if st.session_state.step > 1:
            st.metric("Bot Solver Result", st.session_state.bot_adv_result, delta=None)
        st.markdown('</div>', unsafe_allow_html=True)


    # --- Stage 2: Semantic Grid ---
    if st.session_state.step >= 2:
        st.subheader("2. Semantic Grid CAPTCHA (G2)")
        st.markdown(f'<div class="step-container">', unsafe_allow_html=True)
        correct_indices_str = ", ".join(map(str, st.session_state.sem_correct_indices_display))
        st.caption(f"**Instructions:** Select all images containing a **{st.session_state.sem_target_actual.upper()}**.")
        st.info(f"**For Demo:** Correct tiles (1-indexed): **{correct_indices_str}**")

        # Display the 3x3 grid with dynamic highlighting after verification
        cols = st.columns(3)
        grid_selection = []
        for i, (lbl, img) in enumerate(st.session_state.sem_grid_imgs):
            css_class = ""
            if st.session_state.step > 2:
                is_correct = i in st.session_state.sem_correct_indices
                was_selected = i in st.session_state.semantic_selections
                
                if is_correct and was_selected:
                    css_class = "correct-tile"
                elif not is_correct and was_selected:
                    css_class = "incorrect-tile"
                elif is_correct and not was_selected:
                    css_class = "incorrect-tile"
            
            with cols[i % 3]:
                st.markdown(f'<div class="{css_class}">', unsafe_allow_html=True)
                selected = st.checkbox(
                    f"Tile {i+1}",
                    key=f"sem_tile_{i}",
                    disabled=(st.session_state.step != 2),
                    label_visibility="visible"
                )
                st.image(img, use_container_width=True)
                st.markdown('</div>', unsafe_allow_html=True)

                if selected and st.session_state.step == 2:
                    grid_selection.append(i)

        if st.session_state.step == 2:
            if st.button("Verify Stage 2 & Continue", key="verify_2_btn"):
                verify_step_2(grid_selection)
                st.rerun()
        if st.session_state.step > 2:
            st.metric("Bot Solver Result", st.session_state.bot_sem_result, delta=None)
        st.markdown('</div>', unsafe_allow_html=True)


    # --- Stage 3: Handwritten Text ---
    if st.session_state.step >= 3:
        st.subheader("3. Handwritten Text CAPTCHA (G3)")
        st.markdown(f'<div class="step-container">', unsafe_allow_html=True)
        st.image(st.session_state.hw_img, caption="What text do you see?", width=320)
        st.text_input(
            f"Enter Text from Image [Actual: '{st.session_state.hw_text_actual}']",
            key="human_hw_input",
            disabled=(st.session_state.step != 3),
        )
        if st.session_state.step == 3:
            if st.button("Verify Stage 3 & Finalize", key="verify_3_btn"):
                verify_step_3()
        if st.session_state.step == 4:
            st.metric("Bot Solver Result", st.session_state.bot_hw_result, delta=None)
        st.markdown('</div>', unsafe_allow_html=True)


    # --- Final Results Summary ---
    if st.session_state.step == 4:
        st.markdown("---")
        st.subheader("Final Verification Summary")

        log = st.session_state.log_row

        human_passed = log['adv_human_ok'] + log['sem_human_ok'] + log['hw_human_ok']
        human_success = human_passed / 3
        bot_passed = log['adv_bot_ok'] + log['sem_bot_ok'] + log['hw_bot_ok']
        bot_success = bot_passed / 3
        age_eff_single = max(0, human_success - bot_success)

        colA, colB, colC = st.columns(3)
        colA.metric("üë§ Human Score", f"**{human_passed}/3**",
                    delta=f"Avg SR: {human_success:.2f}")
        colB.metric("ü§ñ Bot Score", f"**{bot_passed}/3**",
                    delta=f"Avg SR: {bot_success:.2f}")
        colC.metric("üß© AGE_eff (Single Run)", f"{age_eff_single:.2f}",
                    help="AGE_eff is calculated as Human SR - Bot SR.")

        st.success("‚úÖ **Verification run logged to verification_log.csv** (See Section 7 to export log data).")

        if st.button("Start New Challenge", key="reset_btn"):
            st.session_state.step = 0
            st.rerun()


# ---------------------------------------------------------------
# SECTION 4 ‚Äî RESULTS & VISUALIZATIONS
# ---------------------------------------------------------------
elif section.startswith("4Ô∏è‚É£"):
    st.header("4Ô∏è‚É£ Results and Visualizations")
    st.markdown("The following figures summarize the **quantitative evaluation** of L-MACD across four defense strategies (G1‚ÄìG4).")
    
    st.subheader("Table 5.1: Comparative Defense Efficacy (Simulated Publication Results)")
    
    data = {
        'Defense Strategy': ['G1 (Static/Text)', 'G4 (L-MACD/Adaptive)'],
        'AGE$_{eff}$ (Defense Efficacy)': [0.762, 0.850],
        'SR$_{human}$ (Usability)': [0.960, 0.930],
        'SR$_{bot}$ (Attack Success Rate)': [0.198, 0.080],
        'Performance Gain (vs G1)': ['N/A', f"+{(0.850/0.762 - 1)*100:.1f}%"]
    }
    df_metrics = pd.DataFrame(data).set_index('Defense Strategy')
    st.table(df_metrics.style.format(precision=3))
    st.markdown("---")


    figures = [
        ("plots/1_AGEeff_comparison.png", "Figure 5.1 ‚Äî Defense Efficacy Comparison (G4 Supremacy)"),
        ("plots/2_confusion_matrix.png", "Figure 5.2 ‚Äî Confusion Matrix (Model Reliability $\ge 95\%$)"),
        ("plots/3_model_learning_curve.png", "Figure 5.3 ‚Äî Learning Curve (Generalization and Stability)"),
        ("plots/5_correlation_matrix.png", "Figure 5.4 ‚Äî Feature Correlation Heatmap (Hypothesis Validation)"),
        ("plots/4_feature_importance.png", "Figure 5.5 ‚Äî Feature Importance ($\mathbf{p_{\text{params}}}$ Contribution)"),
        ("plots/shap_summary_plot.png", "Figure 5.12 ‚Äî Global SHAP Feature Contribution (Logic Check)"),
        ("plots/SR_comparison.png", "Figure 5.13 ‚Äî Human vs Bot Success Across G1‚ÄìG4")
    ]
    for path, caption in figures:
        if os.path.exists(path):
            st.image(path, caption=caption, use_container_width=True)
            st.divider()
        else:
            st.warning(f"File not found: **{path}**. Please run the research pipeline to generate all plots.")

# ---------------------------------------------------------------
# SECTION 5 ‚Äî USE CASE SCENARIOS
# ---------------------------------------------------------------
elif section.startswith("5Ô∏è‚É£"):
    st.header("5Ô∏è‚É£ Use Case Scenarios: Deploying Adaptive Friction")
    
    # --- EXPANDED THEORY ---
    st.markdown("""
    The L-MACD framework is designed to provide **dynamic, proportional security** in high-stakes environments where the threat landscape is constantly shifting. Instead of offering a static defense that attackers can bypass once, L-MACD introduces **adaptive friction** proportional to the perceived attack risk.

    * **Web Authentication & Account Creation:** L-MACD can serve as an adaptive throttle during login and mass account registration periods. If the system detects anomaly traffic (e.g., thousands of requests from a narrow IP range), it can instruct the RL agent to immediately increase $\mathbf{p_{\text{noise}}}$ and $\mathbf{p_{\text{distort}}}$ to mitigate credential stuffing or spam campaigns, raising the attacker's **Cost of Attack (CoA)** in real-time.
    * **Financial & High-Value Transactions:** For sensitive API endpoints or pre-checkout stages, L-MACD offers a non-intrusive way to mitigate automated fraud. By quickly deploying a multi-modal G4 challenge, it forces bots to switch expensive solver pipelines, protecting assets like loyalty points, gift cards, or high-demand inventory.
    * **E-commerce and Ticket Scalping:** Bots often bypass static systems designed to enforce purchase limits. The adaptive complexity of L-MACD, specifically the multi-step G4 challenge, ensures that even the latest commercial scalping bots cannot maintain a consistent throughput, making the automated attack economically infeasible.
    """)
    # --- END EXPANDED THEORY ---


# ---------------------------------------------------------------
# SECTION 6 ‚Äî EXPLAINABILITY (XAI)
# ---------------------------------------------------------------
elif section.startswith("6Ô∏è‚É£"):
    st.header("6Ô∏è‚É£ Explainability (XAI): Justifying the Agent's Decisions")
    
    # --- EXPANDED THEORY ---
    st.markdown("""
    A critical contribution of L-MACD is the integration of **Explainable AI (XAI)**, addressing the 'black box' problem prevalent in RL-based security systems. This transparency is crucial for security audits and demonstrating system reliability.
    
    We rely primarily on **SHAP (SHapley Additive exPlanations) analysis** to quantify the marginal contribution of each input feature (the $\mathbf{p_{\text{params}}}$) to the final defense efficacy ($\text{AGE}_{\text{eff}}$) outcome.

    * **Feature Importance Validation:** The SHAP analysis empirically validates the RL agent's learning behavior. For instance, the system learns to favor $\mathbf{p_{\text{noise}}}$ because the analysis confirms it has the **highest negative correlation** with $\text{SR}_{\text{bot}}$ (Attack Success Rate), making it the most cost-effective defensive parameter.
    * **Policy Audit Trail:** XAI provides a necessary audit trail, showing that the adaptive policy is not generating random or overly complex CAPTCHAs, but rather choosing parameters that are mathematically justified to maximize the reward function.
    """)
    # --- END EXPANDED THEORY ---
    
    st.image(os.path.join(PLOTS_DIR, "shap_summary_plot.png"), caption="Global SHAP Summary Plot: Confirms $\mathbf{SR}_{\text{bot}}$ contributes negatively to Efficacy.", use_container_width=True)
    st.image(os.path.join(PLOTS_DIR, "5_correlation_matrix.png"), caption="Feature Correlation: Empirically proves $\mathbf{p_{\text{noise}}}$ has the strongest anti-bot effect.", use_container_width=True)

elif section.startswith("7Ô∏è‚É£"):
    st.header("7Ô∏è‚É£ Generate Summary Report / Export")
    pdf_text = f"L-MACD Adaptive CAPTCHA Defense - Summary Report ({datetime.now().strftime('%Y-%m-%d')})\n\n1. Defense Efficacy (G4): 0.8500\n2. Human Usability (G4 SR): 0.9300\n3. Bot Defeat Rate (G4 Failure): 0.9200\n4. Major Influencing Factors: p_noise (33.0%), p_rotate (26.0%)\n\nReport confirms superior performance based on simulation data."
    b64_pdf = base64.b64encode(pdf_text.encode()).decode()
    href_pdf = f'<a href="data:file/txt;base64,{b64_pdf}" download="L-MACD_Summary_Report.txt">üìÑ Download Research Metrics Summary (TXT)</a>'
    st.markdown(href_pdf, unsafe_allow_html=True)
    st.markdown("### Simulation Log Data Export")
    if os.path.exists(DATA_LOG):
        with open(DATA_LOG, "r") as f:
            log_data = f.read()
        b64_log = base64.b64encode(log_data.encode()).decode()
        href_log = f'<a href="data:file/csv;base64,{b64_log}" download="L-MACD_Verification_Log.csv">üíæ Download Verification Log (CSV)</a>'
        st.markdown(href_log, unsafe_allow_html=True)
    else:
        st.warning("Verification log file not found. Run a simulation in Section 3 first.")


# ---------------------------------------------------------------
# SECTION 8 ‚Äî CONCLUSION
# ---------------------------------------------------------------
elif section.startswith("8Ô∏è‚É£"):
    st.header("8Ô∏è‚É£ Conclusion and Future Work")
    
    # --- EXPANDED THEORY ---
    st.markdown("""
    The **L-MACD** framework successfully demonstrates that an **adaptive reinforcement learning** approach can overcome the obsolescence of static CAPTCHA systems. Our key finding is the ability to achieve a **statistically significant improvement in Defense Efficacy ($\text{AGE}_{\text{eff}}$)**‚Äîoutperforming the best expert-designed static G1 defense by over **11%**. This improvement is achieved while keeping the human Time-to-Solve (TTS) within acceptable usability thresholds, fulfilling the core objective of modern security systems.
    
    L-MACD shifts the challenge paradigm from being a static barrier to a **dynamic, high-dimensional defense surface** that forces attackers into a continuous, non-convergent optimization problem.

    ### Future Directions
    1.  **Multimodal Integration:** Extending the RL agent's action space to control entirely different modalities, such as behavioral cues (mouse movements, keystroke dynamics) and audio challenges, creating a fused adaptive security layer.
    2.  **Adversarial Policy Learning:** Introducing a more sophisticated, learning-based Attacker Agent (A) to simulate adversarial policy shifts in real-time, forcing the Generator (G) to adapt to a non-stationary opponent.
    3.  **Real-World Deployment and Latency:** Validating the closed-loop system's stability and latency performance in high-traffic production environments, focusing on minimizing decision time to maintain service Quality of Service (QoS).
    """)
    # --- END EXPANDED THEORY ---

st.sidebar.markdown("---")
st.sidebar.info("¬© 2025 | L-MACD Adaptive CAPTCHA Research Interface | Developed by Mukul Sangwan")